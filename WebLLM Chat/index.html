<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebLLM Chat</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #f0f0f0;
        }
        #chat-container {
            width: 350px;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }
        #chat-header {
            background-color: #4A90E2;
            padding: 10px;
            color: white;
            text-align: center;
        }
        #chat-output {
            height: 300px;
            overflow-y: scroll;
            padding: 15px;
            border-bottom: 1px solid #ddd;
        }
        #chat-input {
            display: flex;
            padding: 10px;
        }
        #chat-input input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        #chat-input button {
            padding: 10px;
            background-color: #4A90E2;
            color: white;
            border: none;
            border-radius: 5px;
            margin-left: 5px;
            cursor: pointer;
        }
    </style>
</head>
<body>

<div id="chat-container">
    <div id="chat-header">
        WebLLM Chat
    </div>
    <div id="chat-output">
        <p><strong>System:</strong> You are a helpful AI assistant.</p>
    </div>
    <div id="chat-input">
        <input type="text" id="userInput" placeholder="Type your message...">
        <button onclick="sendMessage()">Send</button>
    </div>
</div>

<script type="module">
    import * as webllm from "https://esm.run/@mlc-ai/web-llm";

    const chatOutput = document.getElementById('chat-output');

    async function sendMessage() {
        const userInput = document.getElementById('userInput').value;
        if (!userInput.trim()) return;
        
        // Display user's message
        const userMessage = document.createElement('p');
        userMessage.innerHTML = `<strong>User:</strong> ${userInput}`;
        chatOutput.appendChild(userMessage);
        document.getElementById('userInput').value = '';

        // Fetch AI response using WebLLM
        const engine = await webllm.CreateMLCEngine("Llama-3.2-8B-Instruct-q4f32_1-MLC");
        const messages = [
            { role: "system", content: "You are a helpful AI assistant." },
            { role: "user", content: userInput }
        ];
        
        const reply = await engine.chat.completions.create({ messages });
        const aiMessage = document.createElement('p');
        aiMessage.innerHTML = `<strong>AI:</strong> ${reply.choices[0].message}`;
        chatOutput.appendChild(aiMessage);

        // Scroll to the latest message
        chatOutput.scrollTop = chatOutput.scrollHeight;
    }
</script>

</body>
</html>
